+++
title = 'TensorTales'
subtitle = "Introducing TensorTales"
date = 2024-03-17T14:48:38-05:00
draft = true
+++

![who-starts-a-conversation](/posts/tensor_tales/who_starts_a_conversation.png)

I've always loved machine learning. Something about it has always felt like
magic. When I first learned about prediction machines, in high school, to me, they always conjured
images of [The Oracle of Delphi](https://en.wikipedia.org/wiki/Pythia) or one
of those old cartoons with a group of magicians huddled around a crystal ball.
Ask the right questions, cast the right spells in the right order, and the
seemingly impossible, a glimpse of the future, could be yours.

As I delve deeper into the field, I increasingly find opportunities to work
alongside, and learn from, the master magicians. The further I progress,
however, the more crucial it becomes to slowly remove the magic. Sometimes,
I have to peek behind the stage curtains to diagnose a bug.  Sometimes, I have
to open the very box from which white rabbits popped out moments earlier, to
identify a mislabeled piece of training data. Sometimes it's necessary to look
up the magician's sleeves to get a better understanding of the strengths and
weaknesses of an approach. Machine learning isn't necessary magic and the
magicians I've had the privilege to meet in person are incredibly talented
individuals, and they're unusually eager to assist newcomers like me. I've
discovered that machine learning practitioners and academics are, on average,
a welcoming and conversational community. Coming from a non-traditional
background, I cannot express enough how much their generous assistance has
meant to me. I'm grateful to be able to call many of them my peers, mentors, or
role models.

Over the years, I've learned an immeasurable amount from blogs.  When I read
the great blogs of [Alex Alemi](https://blog.alexalemi.com), [Chris
Stucchio](https://www.chrisstucchio.com/blog/), or [Terry
Tao](https://terrytao.wordpress.com/), I get the same feeling I get in person.
I get feeling the authors are really trying to have a conversation with the
reader. Like in person, the intent of the author is to help the reader
understand something they didn't understand before. While it's a one-way
conversation this time, it is a conversation none-the-less. 

When I read academic papers, however, I don't get the same sense of
conversation. I agree with Alex Alemi when [he
writes](https://blog.alexalemi.com/blogging.html):

> If we're being even more honest, unfortunately, it seems as though most
> scientific papers these days are not really meant to be read. It doesn't feel
> as though they go out of their way to make themselves understood. I'm sure
> there is some selection bias but I feel as though when I read older papers
> they feel a lot more like a conversation with the author. I feel as though
> the best papers feel as though they are a chat with the author(s) and they
> are essentially helping you stand on their shoulders.

Papers _feel_ different. And I think sometimes, when I read papers in machine learning, the magician is repeating, more or less, the central tenant of being a magician

> "A good magician never reveals their secrets"

As a field, machine learning is going through a somewhat strange arms race. 


Some Magicans are more honest than others about their understanding. Noam Shazeer [writes](https://arxiv.org/pdf/2002.05202.pdf)

> We offer no explanation as to why these architectures seem to work; we
> attribute their success, as all else, to divine benevolence.












